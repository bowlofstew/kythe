---
title: Indexing JavaScript with Flow, part two
author: zarko
layout: post
---

We'll use the Kythe verifier to check that our indexer is working properly.

In the http://www.kythe.io/2015/07/13/flow/[previous article] in this series,
we built a small extension to http://flowtype.org/[Flow] that we used to
generate simple cross-references for a single source file. We checked that those
cross-references were correct by inspecting the resulting Kythe graph in
the sample code browser.

Before we add any more features to the JavaScript indexer, we should take
some time to automate the process of checking the graph. That way, we can
document exactly what we expect to see in our results; we can also be sure
that future changes won't break established features.

== Verification

Most of the work in testing a tool that produces Kythe data boils down to
checking that different anchors in example source text are linked to the correct
nodes and edges. From this starting point, you can make sure that other parts
of the semantic graph are properly formed.

Given a description of these anchors and their desired relationships,
performing the necessary checks doesn't require any information specific to the
language being analyzed. With this in mind, we built the
http://www.kythe.io/docs/kythe-verifier.html[Kythe verifier]. The verifier
accepts a stream of Kythe entries and source files, the latter of which have
been annotated with *goals*. Each goal describes entries that the verifier must
(or must not) find in its input stream. Since some parts of these entries are
uninteresting to test--for example, the exact encoding used for a anchor's VName
is unimportant--parts of a goal may be replaced with variables for which the
verifier will try to find an assignment.

Just as we were able to drive the Kythe pipeline with only a list of JSON
entries, so too can we drive the verifier with only those entries and a list
of goals. This script, `kythe-verify-json.sh`, reads JSON entries from
standard in and passes them (and its arguments) to the verifier:

[source,bash]
----
#!/bin/bash -e
set -o pipefail
# You can find prebuilt binaries at https://github.com/google/kythe/releases.
# This script assumes that they are installed to /opt/kythe.
# Read JSON entries from standard in and pass them to the verifier.
# The entrystream tool turns the JSON into length-delimited protocol buffers,
# described at http://godoc.org/kythe.io/kythe/go/platform/delimited
/opt/kythe/tools/entrystream --read_json | /opt/kythe/tools/verifier "$@"
----

We can write a rule file that checks whether we have any file nodes at all and
call it `test.goals`:

[source,c]
----
//- FileNode.node/kind file
----

The `//-` prefix tells the verifier which lines to look for goals on. It's meant
to be ignored as a comment by most languages. Of course, some languages (like
Python) use different character sequences to denote comments, so it can be
changed with a command-line flag.

We ask the verifier to check that the goals can be met with the entries from
the previous article. Recall that these represent a file (a node with kind
`file`) with the content `Hello, world!'.

[source,bash]
----
echo '
{"source":{"corpus":"example","path":"/hello","language":"js"},
 "fact_name":"/kythe/node/kind","fact_value":"ZmlsZQ=="}
{"source":{"corpus":"example","path":"/hello","language":"js"},
 "fact_name":"/kythe/text","fact_value":"SGVsbG8sIHdvcmxkIQ=="}
' | ./kythe-verify-json.sh test.goals
----

Since we do have a node with kind `file`, the verifier exits with a zero error
code without printing any diagnostics.

If we had written an unsatisfiable goal--let's say we made a spelling mistake
and asked for a node with kind `elif` instead:

[source,c]
----
//- FileNode.node/kind elif
----

the verifier will protest (and return a nonzero exit code):

[role=output]
----
Could not verify all goals. The furthest we reached was:
  test.goals:2:5-2:28 FileNode.node/kind elif
----

For more examples of the goal language, take a look at the code listings in the
http://www.kythe.io/docs/schema[schema document]. There are also lots more in
the $$C++$$ indexer's https://kythe.io/repo/kythe/cxx/indexer/cxx/testdata[testdata]
and the Java indexer's https://kythe.io/repo/kythe/javatests/com/google/devtools/kythe/analyzers/java/testdata[testdata]
directories.

== Verifying JavaScript

We can verify that the `dump-kythe` command that we've 
http://www.kythe.io/2015/07/13/flow/[already built] does what we expect it to
without writing any more OCaml. Let's check that this example file generates
the graph we expect:

[source,js]
----
/* @flow */
function id(x) {
  return x;
}
id("foo");
----

(If you're not already inside a directory with an ancestor containing a Flow
configuration file, you'll need to `touch .flowconfig` in the directory where
you saved the example snippet.)

Recall that the `dump-kythe` command emits a stream of JSON-encoded Kythe
entries. Our `kythe-verify-json.sh` script expects such a stream to pass to
the verifier. Finally, we'll use the source file above (`flow2.js`) as our
rule file. Since there aren't any lines beginning with the `//-` prefix,
the verifier won't have any goals to check, and will (trivially) succeed.

Even without any goals, however, we can get some useful information from the
verifier: by passing the `-annotated_graphviz` flag, we ask the verifier to
emit a http://www.graphviz.org/[Graphviz] graph displaying all the nodes and
relationships found in the input:

[source,bash]
----
./third_party/flow/bin/flow dump-kythe flow2.js \
    | ./kythe-verify-json.sh -annotated_graphviz flow2.js \
    | xdot
----

This graph will render in https://github.com/jrfonseca/xdot.py[xdot.py] as
something like:

+++
include::_posts/images/flow-2-figure-1.svg[]
+++

There are seven nodes here (anchor nodes are abbreviated as `@`); of the three
nodes labelled with VNames, two are our `js/todo` nodes and one is our `file`.
Note that we've selected `/path/of/flow2.js` as both the path and corpus
component of each VName.

Previously, we checked in the sample Web interface that a reference to a
function's argument was linked to the binding of that argument in the function's
definition. Let's have the verifier perform this check instead. We'll amend
the original JavaScript source file by adding comments bearing the special
`//-` prefix:

[source,js]
----
/* @flow */
//- ParamX defines VarX
function id(x) {
//- RefX ref VarX
  return x;
}
id("foo");
----

These goals look for three nodes, which we will refer to as `ParamX`, `VarX`,
and `RefX`. There should be an edge called `defines` between `ParamX` and
`VarX` and an edge called `ref` between `RefX` and `VarX`.

The verifier passes, but our rules aren't quite right yet. If we re-run 
with `-annotated_graphviz`, we can see what's happened:

+++
include::_posts/images/flow-2-figure-2.svg[]
+++

We generate two different `defines` and `ref` pairs for `flow2.js`. One concerns
the function `id` and its call site; this is the pair that the verifier has
found. The one that we actually wanted relates the argument `x` with its
use in the `return` statement. Instead of matching any node on the left-hand
side of our `ref` or `defines` edges, let's instead limit the search to only
anchor nodes that identify the specific source text range we really want:

[source,js]
----
/* @flow */
//- @x defines VarX
function id(x) {
//- @x ref VarX
  return x;
}
id("foo");
----

`@x` refers to the `x` on the next line without a prefix. The verifier therefore
still has three variables to search for; `@x` stands in for `ParamX` the first
time and for `RefX` the second time. The difference here is that there are now
some additional constraints the verifier must satisfy that ensure that the nodes
it finds for those variables are anchors corresponding to the right ranges of
source text. If we run it again, we'll find that it has found the nodes and
edges we intended it to find:

+++
include::_posts/images/flow-2-figure-3.svg[]
+++

Now we have our indexer's first unit test. Note how the verifier goals don't
mention any of the internal implementation decisions we've made about the VNames
of anchors, functions, or variables. They also don't mention our temporary
`node/kind` that we called `js/todo`. Once we start to use the `node/kind`
fact to distinguish between functions and variables (in a future post!),
this unit test will still succeed. We may at that point want to add another
constraint to say that `VarX.node/kind variable` to make our demands even more
explicit.

The Kythe verifier offers a language- and indexer-independent way to write tests
and communicate about the expected graph that a Kythe tool should produce.
Remember, we didn't change the JavaScript indexer at all in this post; we only
took the entries it output and passed them to a different tool. In future posts
in this series, we'll write down the behavior we want from the indexer before we
implement it; these test cases will then become part of a suite that we can
quickly run after each change to guard against regressions.
